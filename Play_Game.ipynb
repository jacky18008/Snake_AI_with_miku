{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsienhaochen/anaconda3/envs/py3.6.4/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#numpy\n",
    "import numpy as np\n",
    "\n",
    "#記錄用的小工具\n",
    "import logging\n",
    "\n",
    "#keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Flatten, Permute\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, concatenate, Lambda, Conv2D, Reshape\n",
    "\n",
    "#OpenAI gym\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "# 數學函式庫\n",
    "import math\n",
    "\n",
    "#keras-rl\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.core import Env\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "\n",
    "#讀資料用\n",
    "import os, sys, csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#繪圖\n",
    "import snake\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "#重頭戲來了，我們需要定義一個完整的RL模型，讓keras-rl跟OpenAI gym可以幫我們跑\n",
    "\n",
    "#裡面有些東西是一定要填的，是OpenAI環境模板的規定\n",
    "\n",
    "class Snake_Game(Env):\n",
    "    \n",
    "    #環境的初始化（毫不猶豫，一定要填）\n",
    "    def __init__(self):\n",
    "        \n",
    "        #狀態空間、動作空間，以及reward的定義必須依照gym的資料結構\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.Box(low = 0, high = 3, shape = (8, 8))\n",
    "        self.reward_range = (-1, 1000)\n",
    "        \n",
    "        #障礙物的數目\n",
    "        self.num_of_blocks = 5\n",
    "        \n",
    "        #隨便取個名字，方便我們存資料\n",
    "        self.name = \"Snake\"\n",
    "        \n",
    "        #設定隨機的seed\n",
    "        self.seed()\n",
    "        \n",
    "        #重設遊戲\n",
    "        self.reset()\n",
    "        \n",
    "        \n",
    "    #盤面的重設，一定要填    \n",
    "    def reset(self):\n",
    "        \n",
    "        #建立空白遊戲盤面\n",
    "        self.board = np.zeros(shape=(8, 8))\n",
    "        \n",
    "        \n",
    "        #回合數統計\n",
    "        self.term = 0\n",
    "        \n",
    "        #檯面上有沒有糖果\n",
    "        self.candy = 0\n",
    "        \n",
    "        #初始化盤面--加入蛇、糖果、障礙物\n",
    "        self.initial_each_step()\n",
    "        self.term += 1\n",
    "        \n",
    "        #初始分數\n",
    "        self.score = 0\n",
    "\n",
    "        #表示遊戲結束與否        \n",
    "        self.DONE = False\n",
    "        \n",
    "        #輸掉時畫面全黑\n",
    "        #self.lose_board = np.ones(shape=(8,8))\n",
    "\n",
    "        #回傳初始盤面（gym的規定）\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def initial_each_step(self):\n",
    "        #(Blank, Snake, Candy, Snake_head, Block) = (0, 1, 2, 3, -1)\n",
    "        \n",
    "        # first time, determine the snake location\n",
    "        if self.term == 0:\n",
    "            #print(\"first time, determine the snake location\")\n",
    "            \n",
    "            location_row = np.random.randint(low=0, high=8)\n",
    "            location_column = np.random.randint(low=0, high=6)\n",
    "            self.board[location_row, location_column:location_column+3] = 1\n",
    "            \n",
    "            #define a list to tract the whole snake here, by the way, we put tail in first.\n",
    "            self.snake_list = []\n",
    "            self.snake_list.append((location_row, location_column))\n",
    "            self.snake_list.append((location_row, location_column+1))\n",
    "            self.snake_list.append((location_row, location_column+2))\n",
    "            \n",
    "            #we also need to have to tract head cooperation here.\n",
    "            self.head = (location_row, location_column+2)\n",
    "            self.board[self.head] = 3\n",
    "            #print(\"initial_head: \", self.head)\n",
    "\n",
    "            \n",
    "            # default direction = 3(right)\n",
    "            self.direction = 3\n",
    "            \n",
    "        #put candy if just eaten\n",
    "        if self.candy == 0:\n",
    "            blank_list = np.where(self.board == 0)\n",
    "            candy_index = np.random.randint(blank_list[0].shape[0])\n",
    "            self.board[blank_list[0][candy_index], blank_list[1][candy_index]] = 2\n",
    "            self.candy = 1\n",
    "        \n",
    "        #list all the blank tile on the board\n",
    "        blank_list = np.where(self.board == 0)\n",
    "\n",
    "        if self.term%5 == 0:        \n",
    "            #delete blocks generated last time.\n",
    "            self.board = np.where(self.board == -1, 0, self.board)\n",
    "        \n",
    "            #generate blocks from all the blank tiles\n",
    "            num_of_blank_tiles = blank_list[0].shape[0]\n",
    "            block_list = np.random.randint(num_of_blank_tiles, size=(self.num_of_blocks))\n",
    "            for i in block_list:\n",
    "                self.board[blank_list[0][i], blank_list[1][i]] = -1\n",
    "            \n",
    "        \n",
    "    #每一回合的執行（包括選擇動作、更新現有資產情況、計算reward等等）（一定要填）       \n",
    "    def step(self, action):\n",
    "        \n",
    "        #繪圖用\n",
    "        snake.init()\n",
    "        \n",
    "        #這裡必須回傳特定資料作為紀錄（格式是字典檔），因為我們目前沒有需要，所以隨便設個空的字典檔。\n",
    "        info = dict()\n",
    "        \n",
    "        #reward for this time\n",
    "        reward = 0\n",
    "    \n",
    "        #回合數+1\n",
    "        self.term += 1\n",
    "        \n",
    "        #動作會介在0~3之間，分別set as 0: up, 1: left, 2: down, 3: right。\n",
    "    \n",
    "        # action\n",
    "        #print(\"action:\", action)\n",
    "        if action == 0:\n",
    "            logging.debug(\"Up\")\n",
    "        elif action == 1:\n",
    "            logging.debug(\"Left\")\n",
    "        elif action == 2:\n",
    "            logging.debug(\"Down\")\n",
    "        else: #action == 3\n",
    "            logging.debug(\"Right\")\n",
    "        \n",
    "        #if the action has the same axis with current direction, go that direction.\n",
    "        if action%2 == self.direction%2:\n",
    "            action = self.direction\n",
    "            \n",
    "        #change direction    \n",
    "        self.direction = action\n",
    "        \n",
    "        #vertical axis\n",
    "        #change row value\n",
    "        if action%2 == 0:\n",
    "            #check if exceed board first:\n",
    "            row = self.head[0]\n",
    "            row += action-1\n",
    "            \n",
    "            if row < 8 and row >= 0:\n",
    "                self.head = (row, self.head[1])\n",
    "                #print(self.head)\n",
    "            else:\n",
    "                self.DONE = True\n",
    "                snake.draw( mapArray=self.board, score=self.score, isOver=self.DONE)\n",
    "                return self.get_observation(), -10, self.DONE, info\n",
    "                   \n",
    "        #horizontal axis\n",
    "        #change column value\n",
    "        else:\n",
    "            #check if exceed board first:\n",
    "            column = self.head[1]\n",
    "            column += action-2\n",
    "            \n",
    "            if column < 8 and column >= 0:\n",
    "                self.head = (self.head[0], column)  \n",
    "            else:\n",
    "                self.DONE = True\n",
    "                snake.draw( mapArray=self.board, score=self.score, isOver=self.DONE)\n",
    "                return self.get_observation(), -10, self.DONE, info \n",
    "        \n",
    "            \n",
    "        #blank on target point    \n",
    "        if self.board[self.head] == 0:\n",
    "            #put the new head in the list, pop the tail.\n",
    "            self.snake_list.append(self.head)\n",
    "            pop = self.snake_list.pop(0)\n",
    "            \n",
    "            #update board\n",
    "            \n",
    "            #set all snake -> 1\n",
    "            for grid in self.snake_list:\n",
    "                self.board[grid] = 1\n",
    "                \n",
    "            self.board[self.head] = 3\n",
    "            self.board[pop] = 0\n",
    "            \n",
    "            reward = 0\n",
    "        \n",
    "        #candy on target point\n",
    "        elif self.board[self.head] == 2:\n",
    "            \n",
    "            #put head in queue without pop\n",
    "            self.snake_list.append(self.head)\n",
    "            \n",
    "            #eat candy(update board)\n",
    "            #set all snake -> 1\n",
    "            for grid in self.snake_list:\n",
    "                self.board[grid] = 1\n",
    "                \n",
    "            self.board[self.head] = 3\n",
    "            self.candy = 0\n",
    "            \n",
    "            #reward = 1\n",
    "            reward = 1\n",
    "\n",
    "        \n",
    "        #crash with blocks or its own body    \n",
    "        else:\n",
    "            self.DONE = True\n",
    "            \n",
    "            #put the new head in the list, pop the tail.\n",
    "            self.snake_list.append(self.head)\n",
    "            pop = self.snake_list.pop(0)\n",
    "            \n",
    "            #update board\n",
    "            \n",
    "            #set all snake -> 1\n",
    "            for grid in self.snake_list:\n",
    "                self.board[grid] = 1\n",
    "                \n",
    "            self.board[self.head] = 3\n",
    "            self.board[pop] = 0\n",
    "            snake.draw( mapArray=self.board, score=self.score, isOver=self.DONE)\n",
    "            return self.get_observation(), -10, self.DONE, info\n",
    "        \n",
    "        \n",
    "        #because we will add new bloacks here, we should put it at the end of fcn.\n",
    "        self.initial_each_step()\n",
    "        \n",
    "        #show\n",
    "        #print(self.term, \" step\")\n",
    "        #print(self.get_observation())\n",
    "            \n",
    "        #這裡要回傳什麼，回傳的順序，都是gym規定的\n",
    "        self.score += reward\n",
    "        snake.draw( mapArray=self.board, score=self.score, isOver=self.DONE)\n",
    "        return self.get_observation(), reward, self.DONE, info\n",
    "            \n",
    "            \n",
    "    #定義一個方式，讓環境可以roll出隨機的數字（一定要填）    \n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "    \n",
    "    \n",
    "    #取得當前狀態\n",
    "    def get_observation(self):\n",
    "        #get board for last 20 days\n",
    "        return self.board\n",
    "    \n",
    "    def get_snake_length(self):\n",
    "        return len(self.snake_list)\n",
    "\n",
    "    #這裡是拿來做test時候的顯示（也是一定要填）        \n",
    "    def render(self, mode='human', close=False):\n",
    "        if close:\n",
    "            return\n",
    "        outfile = None\n",
    "        \n",
    "        if self.DONE == True:\n",
    "            outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "            s = \"\"\n",
    "            \n",
    "            for i in range(self.get_observation().shape[0]):\n",
    "                for j in range(self.get_observation().shape[1]):\n",
    "                    s += str(int(self.board[i][j]))\n",
    "                    s += \"  \"\n",
    "                s += \"\\n\"\n",
    "            \n",
    "            outfile.write(s)\n",
    "        return outfile\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "        #self.reset()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# In[4]:\n",
    "\n",
    "#把我們辛苦架好的遊戲環境作為測試環境\n",
    "Snake_env = Snake_Game()\n",
    "nb_actions = Snake_env.action_space.n\n",
    "\n",
    "#這裡的window_length 是指當我需要傳入包括前幾次畫面作為資料時的東西，\n",
    "#他是把它當作CNN的channel數一樣的東西\n",
    "#本來這裡是不需要加的，只是keras-rl寫死了所以我只好傳進去。\n",
    "BOARD_INPUT_SHAPE = (8, 8)\n",
    "WINDOW_LENGTH = 1\n",
    "\n",
    "\n",
    "#另外，由於資料最後一步是keras-rl處理的，他的變數順序這樣寫，\n",
    "#我也只好這樣寫\n",
    "input_shape = (WINDOW_LENGTH,) + BOARD_INPUT_SHAPE \n",
    "\n",
    "#設定輸入層的形狀\n",
    "model_input = Input(shape = input_shape)\n",
    "\n",
    "#視不同的backend要排一下順序\n",
    "if K.image_dim_ordering() == 'tf':\n",
    "    # (width, height, channels)\n",
    "    permute = Permute((2, 3, 1), input_shape=input_shape)\n",
    "elif K.image_dim_ordering() == 'th':\n",
    "    # (channels, width, height)\n",
    "    permute = Permute((1, 2, 3), input_shape=input_shape)\n",
    "    \n",
    "#把排列的結果套用上去，喬一下我們的原始input\n",
    "preprocessed_input = permute(model_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 隨便弄一個model\n",
    "# 雖然很抱歉，不過只有這裡可以改\n",
    "Layer_1 = Dense(16, activation = \"relu\")(preprocessed_input)\n",
    "Layer_2 = Dense(32, activation = \"relu\")(Layer_1)\n",
    "Layer_3 = Dense(64, activation = \"relu\")(Layer_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8, 8, 16)          32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8, 8, 32)          544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8, 8, 64)          2112      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 265,156\n",
      "Trainable params: 265,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#拉直\n",
    "flatten = Flatten()(Layer_3)\n",
    "\n",
    "#soft landing\n",
    "soft_landing = Dense(64, activation=\"relu\")(flatten)\n",
    "\n",
    "#動作有4種，所以最後輸出是4維\n",
    "action = Dense(4, activation=\"linear\")(soft_landing)\n",
    "\n",
    "\n",
    "#把整個model包起來\n",
    "model = Model(model_input, action)\n",
    "\n",
    "json_string = model.to_json()\n",
    "\n",
    "#看看我們包出來的結果\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode?test\n",
      "Step?1000\n"
     ]
    }
   ],
   "source": [
    "#準備要實地測試了：\n",
    "\n",
    "#你可以自己決定模式跟步數\n",
    "mode = input(\"Mode?\")\n",
    "step = int(input(\"Step?\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  1  \n",
      "0  -1  0  0  0  0  0  1  \n",
      "0  0  2  0  0  0  -1  3  \n",
      "0  -1  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "Episode 1: reward: -10.000, steps: 6\n",
      "0  0  0  0  0  0  0  0  \n",
      "3  1  1  1  0  0  0  0  \n",
      "0  0  0  0  0  0  0  -1  \n",
      "0  -1  -1  0  0  0  0  0  \n",
      "0  -1  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  -1  0  2  0  0  0  0  \n",
      "Episode 2: reward: -9.000, steps: 13\n",
      "0  0  0  -1  0  0  0  0  \n",
      "3  1  1  0  0  0  0  0  \n",
      "0  0  0  2  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  -1  0  0  0  0  0  0  \n",
      "0  0  0  -1  0  0  0  0  \n",
      "0  0  0  0  0  0  0  -1  \n",
      "0  0  0  0  0  0  0  0  \n",
      "Episode 3: reward: -10.000, steps: 5\n",
      "0  0  -1  0  0  0  0  -1  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  -1  0  2  0  \n",
      "0  0  0  0  0  0  -1  0  \n",
      "0  0  0  0  0  1  1  3  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  -1  0  0  0  \n",
      "Episode 4: reward: -10.000, steps: 3\n",
      "0  3  0  0  -1  0  0  0  \n",
      "0  1  0  0  0  0  0  0  \n",
      "0  1  0  0  0  0  0  0  \n",
      "0  0  0  -1  0  0  0  0  \n",
      "-1  0  0  -1  0  0  0  0  \n",
      "0  -1  0  0  0  0  0  0  \n",
      "2  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "Episode 5: reward: -10.000, steps: 6\n",
      "0  0  0  0  0  1  1  3  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  -1  0  0  0  0  \n",
      "0  0  0  0  0  -1  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  -1  0  0  0  0  0  \n",
      "0  0  0  0  -1  0  0  -1  \n",
      "0  0  0  0  0  2  0  0  \n",
      "Episode 6: reward: -10.000, steps: 3\n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  -1  0  0  0  0  \n",
      "0  0  0  0  0  1  1  3  \n",
      "0  0  0  0  0  0  -1  0  \n",
      "0  0  0  0  0  2  0  0  \n",
      "0  0  0  0  0  -1  0  0  \n",
      "0  0  0  0  -1  0  0  0  \n",
      "0  0  0  -1  0  0  0  0  \n",
      "Episode 7: reward: -10.000, steps: 3\n",
      "0  0  -1  0  1  1  3  -1  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  2  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  -1  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  -1  0  0  0  0  0  0  \n",
      "Episode 8: reward: -10.000, steps: 1\n",
      "0  0  0  0  0  1  1  3  \n",
      "0  0  0  0  0  2  0  0  \n",
      "-1  0  0  0  0  0  -1  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "-1  0  0  -1  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  -1  0  0  \n",
      "Episode 9: reward: -10.000, steps: 2\n",
      "3  1  0  0  0  -1  0  0  \n",
      "0  1  -1  0  0  0  0  -1  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  0  \n",
      "2  0  0  0  0  0  0  0  \n",
      "0  0  0  0  0  0  0  -1  \n",
      "0  0  0  0  -1  0  0  0  \n",
      "Episode 10: reward: -10.000, steps: 10\n"
     ]
    }
   ],
   "source": [
    "#設定記憶體\n",
    "memory = SequentialMemory(limit=1000000, window_length=1)\n",
    "\n",
    "#設定策略\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=.6, value_min=.1, value_test=.00, nb_steps=step)\n",
    "\n",
    "#DQN設定\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory = memory, policy = policy,\n",
    "               nb_steps_warmup=100, gamma=.90, target_model_update=100)\n",
    "\n",
    "dqn.compile(Adam(lr=.00025), metrics=['mae'])\n",
    "\n",
    "\n",
    "#實際跑看看\n",
    "if mode == 'train':\n",
    "\n",
    "    #儲存權重的一些設定：\n",
    "    weights_filename = 'dqn_{}_weights.h5f'.format(Snake_env.name)\n",
    "    checkpoint_weights_filename = 'dqn_' + Snake_env.name + '_weights2_{step}.h5f'\n",
    "    log_filename = 'dqn_{}_log.json'.format(Snake_env.name)\n",
    "    callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=1000)]\n",
    "    callbacks += [FileLogger(log_filename, interval=100)]\n",
    "\n",
    "\n",
    "    weights = \"dqn_\"+Snake_env.name+\"_weights_\" + str(step) + \".h5f\"\n",
    "    #if weights:\n",
    "    #    weights_filename_1 = weights\n",
    "    #dqn.load_weights(weights_filename_1)\n",
    "\n",
    "\n",
    "    #訓練開始\n",
    "    dqn.fit(Snake_env, callbacks=callbacks, nb_steps=step, log_interval=100, verbose=1)\n",
    "\n",
    "    #把權重存起來\n",
    "    dqn.save_weights(weights_filename, overwrite=True)\n",
    "\n",
    "\n",
    "    \n",
    "elif mode == 'test':\n",
    "    \n",
    "    #讀取權重\n",
    "    weights = \"dqn_\"+Snake_env.name+\"_weights_\" + str(step) + \".h5f\"\n",
    "    if weights:\n",
    "        weights_filename = weights\n",
    "    dqn.load_weights(weights_filename)\n",
    "    dqn.test(Snake_env, nb_episodes=10, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.6.4]",
   "language": "python",
   "name": "conda-env-py3.6.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
